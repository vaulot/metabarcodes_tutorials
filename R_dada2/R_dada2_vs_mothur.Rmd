---
title: "Tutorial - Compare results of Dada2 vs Mothur"
author: "Daniel Vaulot"
date: '`r format(Sys.time(), "%d %m %Y")`'
header-includes:
   - \usepackage{color, fancyvrb}
output:
  rmdformats::readthedown:
    highlight: kate
    number_sections : yes    
  pdf_document: 
    toc: yes
    toc_depth: 2
    number_sections : yes
---

```{r setup}
  knitr::opts_chunk$set(fig.width=6, 
                        fig.height=6, 
                        eval=TRUE, 
                        cache=TRUE,
                        echo=TRUE,
                        prompt=FALSE,
                        tidy=TRUE,
                        comment=NA,
                        message=FALSE,
                        warning=FALSE)

```

# Aim

Compare the results of the analysis by mothur vs dada2
* **Prerequisite** : the R_dada2_tutorial must have been run before

# Directory structure

Relative to the main directory from GitHub

* **../fastq** : fastq files
* **../fastq_filtered** : fastq files after filtration
* **../qual_pdf** : qual pdf files
* **../dada2** : dada2 processed files
* **../databases** : PR2 database files (contains the latest PR2 database formatted for dada2 - https://github.com/vaulot/pr2_database/releases/)
* **../blast** : BLAST files output
* **../img** : Images
* **../R_dada2** : This tutorial


# Tutorial description


## Load the necessary libraries**

```{r, results='hide', message=FALSE}
  library("dada2")
  library("phyloseq") 
  library("Biostrings")
  
  library("ggplot2")
  library("stringr")
  library("dplyr")
  library("tidyr")
  library("readxl")
  library("tibble")
  library("readr")

  library("kableExtra") # necessary for nice table formatting with knitr
```

## Set up directories

```{r}
# change the following line to the path where you unzipped the tutorials

# ngs directory
  ngs_dir <- "../fastq_carbom"
```
  

## Primers

Note that the primers are degenerated.  Dada2 has an option to remove primers (FilterandTrim) but this function will not accept degeneracy.  

```{r}
  primer_set_fwd = c("CCAGCAGCCGCGGTAATTCC", "CCAGCACCCGCGGTAATTCC", 
                     "CCAGCAGCTGCGGTAATTCC", "CCAGCACCTGCGGTAATTCC")
  primer_set_rev = c("ACTTTCGTTCTTGATYRATGA")
  primer_length_fwd <- str_length(primer_set_fwd[1]) 
  primer_length_rev <- str_length(primer_set_rev[1])
```

## PR2 tax levels

```{r}
  PR2_tax_levels <- c("Kingdom", "Supergroup","Division", "Class", 
                      "Order", "Family", "Genus", "Species")
```


## Examine the fastQ files

### Construct a list of the fastq files

It is assumed that the sample names are at the start of file name and separated by _.

```{r}
# get a list of all fastq files in the ngs directory and separate R1 and R2
  fns <- sort(list.files(ngs_dir, full.names = TRUE)) 
  fns <- fns[str_detect( basename(fns),".fastq")]
  fns_R1 <- fns[str_detect( basename(fns),"R1")]
  fns_R2 <- fns[str_detect( basename(fns),"R2")]

# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
  sample.names <- str_split(basename(fns_R1), pattern = "_", simplify = TRUE) 
  sample.names <- sample.names[,1]

```
### Compute number of paired reads

```{r, warning=FALSE}
# create an empty data frame  
  df <- data.frame()  

# loop throuh all the R1 files (no need to go through R2 which should be the same) 

  for(i in 1:length(fns_R1)) { 
    
    # use the dada2 function fastq.geometry
      geom <- fastq.geometry(fns_R1[i])
      
    # extract the information on number of sequences and file name 
      df_one_row <- data.frame (n_seq=geom[1], file_name=basename(fns[i]) )
      
    # add one line to data frame
      df <- bind_rows(df, df_one_row)
 } 
# display number of sequences and write data to small file
  knitr::kable(df)
  # write.table(df, file = "n_seq.txt", 
  #             sep="\t", row.names = FALSE, na="", quote=FALSE)

# plot the histogram with number of sequences
  ggplot(df, aes(x=n_seq)) + 
        geom_histogram( alpha = 0.5, position="identity", binwidth = 10) +
        xlim(0, 2000)
```

### Plot quality for reads

```{r}
 for(i in 1:length(fns)) { 
   
  # Use dada2 function to plot quality
    p1 <- plotQualityProfile(fns[i])
    
  # Only plot on screen for first 2 files  
    if (i <= 2) {print(p1)}
    
  # save the file as a pdf file (uncomment to execute)
    # p1_file <- paste0(ngs_dir,"/qual/",basename(fns[i]),".pdf")
    # ggsave( plot=p1, filename= p1_file, 
    #           device = "pdf", width = 15, height = 15, scale=1, units="cm")
  }   

```

## Filter and Trim the reads 

**Note** : We recommend to use **cutadapt** to remove the primers : http://cutadapt.readthedocs.io/en/stable/guide.html#.  
The program is really very powerful.


### Create names for the filtered files in filtered/ subdirectory of the fastq carbom
```{r}
  filt_dir <- file.path(ngs_dir, "filtered")

  filt_R1 <- file.path(filt_dir, paste0(sample.names, "_R1_filt.fastq"))
  filt_R2 <- file.path(filt_dir, paste0(sample.names, "_R2_filt.fastq"))
```  
  
### Removing the primers by sequence

The dada2 algorithm requires primers to be removed prior to processing.

The next piece of code could be used to remove the primers by **sequence**.  The dada2 package does not allow for primer degeneracy.  Since our forward primer is degenerated at two positions, all four combinations need to be tested.  However it will be necessary to re-assemble after that the 4 fastQ files created (which has not to done).  So the better strategy is to remove primer by trunction (see next step).

```{r}
# On Windows set multithread=FALSE  

  out_all <-data.frame(id=length(fns_R1))
  for (i in 1:4) {
    out <- filterAndTrim(fns_R1, filt_R1, fns_R2, filt_R2, truncLen=c(250,240), trimLeft = c(0,0),
              maxN=0, maxEE=c(Inf, Inf), truncQ=10, rm.phix=TRUE, primer.fwd = primer_set_fwd[i], 
              compress=FALSE, multithread=FALSE) 
    out_all <- cbind(out_all, out)

  }
```



```{r}
  knitr::kable(out_all,"latex")%>%
         kable_styling(bootstrap_options = "striped", font_size = 7)
```




The table shows the number of sequences recognized by each primer combination.


###  Remove primers by truncation and filter

Filter all sequences with N, truncate R2 to 240 bp 

```{r}
  out <- filterAndTrim(fns_R1, filt_R1, fns_R2, filt_R2, 
                       truncLen=c(250,240), trimLeft = c(primer_length_fwd,primer_length_rev),
                       maxN=0, maxEE=c(2, 2), truncQ=10, rm.phix=TRUE,  
                       compress=FALSE, multithread=FALSE) 
```

## Dada2 processing
    
### Learn error rates

The error rates are plotted.

```{r}
  err_R1 <- learnErrors(filt_R1, multithread=FALSE)

  plotErrors(err_R1, nominalQ=TRUE)
  
  err_R2 <- learnErrors(filt_R2, multithread=FALSE)

  plotErrors(err_R2, nominalQ=TRUE)
```

### Dereplicate the reads

```{r}
  derep_R1 <- derepFastq(filt_R1, verbose=FALSE)
  derep_R2 <- derepFastq(filt_R2, verbose=FALSE)
  
# Name the derep-class objects by the sample names
  names(derep_R1) <- sample.names
  names(derep_R2) <- sample.names 
```

### Sequence-variant inference algorithm to the dereplicated data
   
```{r}
    dada_R1 <- dada(derep_R1, err=err_R1, multithread=FALSE)
    dada_R2 <- dada(derep_R2, err=err_R2, multithread=FALSE)
    
    dada_R1[[1]]
    dada_R2[[1]]
```

### Merge sequences 


```{r}
    mergers <- mergePairs(dada_R1, derep_R1, dada_R2, derep_R2, verbose=TRUE)
    
  # Inspect the merger data.frame from the first sample
    knitr::kable(head(mergers[[1]]) )
```


### Make sequence table 

```{r}
    seqtab <- makeSequenceTable(mergers)
    
    dim(seqtab)
    
  # Make a transposed of the seqtab to make it be similar to mothur database
    t_seqtab <- t(seqtab)

  # Inspect distribution of sequence lengths
    table(nchar(getSequences(seqtab))) 
```

### Remove chimeras

Note that remove chimeras will produce spurious results if primers have not be removed.  The parameter `methods` can be `pooled` or `consensus`
```{r}
    seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=FALSE, verbose=TRUE)

  # Compute % of non chimeras
    paste0("% of non chimeras : ",sum(seqtab.nochim)/sum(seqtab))
    paste0("total number of sequences : ",sum(seqtab.nochim))
    
```
In our case there were no chimeras found.  It is noteworthy that the total number of sequences is almost twice that what is recovered with **mothur** which is **2573**

### Track number of reads at each step
```{r}
  # define a function
    getN <- function(x) sum(getUniques(x))
    
    track <- cbind(out, sapply(dada_R1, getN), sapply(mergers, getN), 
                   rowSums(seqtab), rowSums(seqtab.nochim))

    colnames(track) <- c("input", "filtered", "denoised", "merged", "tabled", "nonchim")
    rownames(track) <- sample.names
    
    knitr::kable(track)  
```

  

### Assigning taxonomy

```{r}
    pr2_file <- paste0("../databases/pr2_version_4.72_dada2_Eukaryota.fasta.gz")
    taxa <- assignTaxonomy(seqtab.nochim, refFasta=pr2_file,  
                           taxLevels = PR2_tax_levels,
                           minBoot = 0, outputBootstraps = TRUE,
                           verbose = TRUE)
```

### Export data as produced by Dada2

```{r}
  write_tsv(as.tibble(taxa$tax), path = "taxa.txt")  
  write_tsv(as.tibble(taxa$boot), path = "taxa_boot.txt")
  write_tsv(as.tibble(seqtab.nochim), path = "seqtab.txt")
```

### Changing OTU names from sequence to Otuxxxx

In the OTU put of dada2, otu names are the sequences.  We change to give a Otuxxx name and the sequences are stored in the taxonomy table.

```{r}
    taxa_tax <- as.data.frame(taxa$tax)
    taxa_boot <- as.data.frame(taxa$boot)

    taxa_tax <- taxa_tax %>%  rownames_to_column(var = "sequence") %>%
                              rowid_to_column(var = "OTUNumber") %>%
                              mutate(OTUNumber = sprintf("otu%04d", OTUNumber))
    row.names(taxa_tax) <- taxa_tax$OTUNumber
    row.names(taxa_boot) <- taxa_tax$OTUNumber    

  # Transpose matrix of abundance
    seqtab.nochim_trans <- as.data.frame(t(seqtab.nochim))
    row.names(seqtab.nochim_trans) <- taxa_tax$OTUNumber

```


### Filter for 18S

Remember that we sequenced 3 genes (18S, 16S plastid and nifH.  We remove the sequences are not 18S by selecting only bootstrap value for Supergroup in excess of 80. 

```{r}
    bootstrap_min <- 80

  # Filter based on the bootstrap
    taxa_tax_18S <- taxa_tax[taxa_boot$Supergroup >= bootstrap_min,]
    taxa_boot_18S <- taxa_boot[taxa_boot$Supergroup >= bootstrap_min,]



  # Filter matrix of abundance by removing row for which Supergroup bootstrap < min
    seqtab.nochim_18S <- seqtab.nochim_trans[taxa_boot$Supergroup >= bootstrap_min,]
  
  # Create a database like file for dada2
    dada2_database <-   cbind(taxa_tax_18S, seqtab.nochim_18S)

```


## Phyloseq

### Create a phyloseq object for dada2

```{r}
samdf <- data.frame(sample_name=sample.names)
rownames(samdf) <- sample.names

ps_dada2 <- phyloseq(otu_table(as.matrix(seqtab.nochim_18S), taxa_are_rows=TRUE), 
               sample_data(samdf), 
               tax_table(as.matrix(select(taxa_tax_18S, - sequence, -OTUNumber))))
```

### Create a phyloseq object for the mothur results

```{r}
# read the mothur database from Excel file
  mothur_file <- "../Comparison different methods 1.0.xlsx"
  mothur_database <- read_excel(mothur_file, sheet="mothur")
# need to remove empty rows
  mothur_database <- mothur_database %>% filter(!is.na(OTUNumber))

# create the taxonomy matrix  
  mothur_tax <- str_split(mothur_database$OTUConTaxonomy, ";", 9, simplify = TRUE)
# the last column is empty so remove  
  mothur_tax <- mothur_tax[,1:8 ]   
  
# give row names and column names
  colnames(mothur_tax) <- PR2_tax_levels
  rownames(mothur_tax) <- mothur_database$OTUNumber 
  
# replace in the database, the unique taxonomy column by 8 columns
  mothur_database <- cbind(mothur_database, mothur_tax)
  mothur_database <- mothur_database %>% select(-OTUConTaxonomy)
 
# create the otu_table
  mothur_otu <- select(mothur_database, ends_with("p"),-Supergroup)
  rownames(mothur_otu) <- mothur_database$OTUNumber
  mothur_otu <- as.matrix(mothur_otu)

# create the phyloseq for mothur  
  ps_mothur <- phyloseq(otu_table(mothur_otu, taxa_are_rows=TRUE), 
               sample_data(samdf), 
               tax_table(mothur_tax))
```

### Compare at the division level

```{r}
  # remove Lobosa only found in Mothur
  ps_mothur_common <- subset_taxa(ps_mothur, !(Division %in% c("Lobosa")))
  
  plot_bar(ps_mothur_common, fill = "Division") + 
    geom_bar(aes(color=Division, fill=Division), stat="identity", position="stack") +
    ggtitle("Mothur")
  plot_bar(ps_dada2, fill = "Division") + 
    geom_bar(aes(color=Division, fill=Division), stat="identity", position="stack") +
    ggtitle("Dada2")


```
## Compare by aggregation

### Transform the database files into the long version

```{r}
  dada2_long <- dada2_database %>% gather(key = "sample", value="n_seq", num_range(120:200,"p"))  %>%
                                   select(-sequence)
  knitr::kable(head(dada2_long), "latex") %>%
         kable_styling(bootstrap_options = "striped", font_size = 7)

  mothur_long <- mothur_database %>% gather(key = "sample", value="n_seq", num_range(120:200,"p"))  %>%
                                   select(-contains("repSeq"), -nseq)
  knitr::kable(head(mothur_long), "latex")  %>%
         kable_styling(bootstrap_options = "striped", font_size = 7)


```

### Aggregate by Division, Class, Genus, Species

```{r}
  dada2_species <- dada2_long %>% group_by(Division, Class, Genus, Species) %>%
                                   summarize (n_seq = sum(n_seq))
  knitr::kable(head(dada2_species))

  mothur_species <- mothur_long %>% group_by(Division, Class, Genus, Species) %>%
                                   summarize (n_seq = sum(n_seq))
  knitr::kable(head(mothur_species))

```

### Merge the two lists to comute the relation between mothur and dada2 estimates

```{r, warning=FALSE}
  both_species <- rbind(dada2_species, mothur_species) %>% 
                        group_by(Division, Class, Genus, Species) %>%
                        summarize (n_methods = n()) %>%
                        left_join(dada2_species) %>%
                        dplyr::rename (dada2 = n_seq) %>%
                        left_join(mothur_species) %>%
                        dplyr::rename (mothur = n_seq) %>%
                        arrange(desc(dada2))
  both_class <- both_species %>%  group_by(Division, Class) %>%
                                  summarise(dada2=sum(dada2, na.rm = TRUE), mothur=sum(mothur, na.rm = TRUE))%>%
                                  arrange(desc(dada2))
```

### Plot at Class level

```{r}
  
  
  ggplot(both_class) + geom_point(aes(mothur,dada2)) +
                         geom_smooth(aes(mothur,dada2), method = "lm", show.legend = TRUE) +
                         ggtitle ("Class level count")
  
  summary(lm(both_class$dada2 ~ both_class$mothur))

```
  
### Plot at Species level


```{r}


  ggplot(both_species) + geom_point(aes(mothur,dada2)) +
                       geom_smooth(aes(mothur,dada2), method = "lm", show.legend = TRUE) +
                       ggtitle ("Species level count")

  summary(lm(both_species$dada2 ~ both_species$mothur))
    
  species_one_method <- both_species %>% filter(n_methods==1) 
  knitr::kable(species_one_method, "latex")%>%
         kable_styling(bootstrap_options = "striped", font_size = 7)

```


# Conclusion on the dada2 pipeline

* The dada2 pipeline yieds 1.7 more reads than mothur
* The number of reads at the species and class levels are correlated
* It is very fast, the longest step is the taxonomy assignement
* It offers the advantage of having everything performed under R. 

